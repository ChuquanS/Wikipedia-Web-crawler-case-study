# Wikipedia-Web-crawler-case-study
Wikipedia Crawl Automation Implemention 

### When using Wikipedia, it's interesting that clicking and reading all articles will take a lot of time. We will be working to automate this process by using a program that gives us access to Wikipedia, tracking the first link on each page, and seeing where these links lead. To achieve this, we need to understand how web pages work and the Python tools we can use to interact with web and web content.

### Three potential results will appear when doing this manually:
   #### -- Search will end in the "Philosophy" Wikipedia page
   #### -- Search will start repeating as the same word appears as the first link (loops)
   #### -- Search comes to a page without further link

##### 使用维基百科时，有趣的是单击和阅读所有文章需要很多时间。 我们将致力于使这一过程实现自动化，借助于一个为我们查阅维基百科的程序，跟踪每个页面上的第一个链接，以及看到这些链接的导向位置。为了实现这一点，我们需要了解网络页面的工作原理和我们可以用于与网络和网络内容交互的一些 Python 工具。
